<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">  
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Xuecheng Wu's Homepage</title>
  <link href="css/bootstrap.css" rel='stylesheet' type='text/css' />
  <link rel="shortcut icon" type="image/x-icon" href="images/misc/personal.png">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
  <!-- Bulma Version 0.7.5-->
  <link rel="stylesheet" href="https://unpkg.com/bulma@0.7.5/css/bulma.min.css" />
  <link href='css/style.css?_t=20200916' rel='stylesheet' type='text/css'>
  <script defer src="font-awesome/js/brands.min.js"></script>
  <script defer src="font-awesome/js/regular.min.js"></script>
  <script defer src="font-awesome/js/fontawesome.min.js"></script>
    <style>
      .red {
        color: rgb(238, 76, 44);
        font-style: normal;
      }
      .blue {
        color: rgb(238, 76, 44);
        font-style: normal;
      }
       
      #intro {
       margin-top: 0em !important;
      }
      
      .content h3 {
       margin-bottom: 1em!important;
       margin-top: 2em!important;
      }

      .content figure {
       width: 90%;
       display: flex;
       align-items: center;
       overflow: hidden;
       margin-left: auto!important;
       margin-right: auto!important;
      }
      
      .columns:not(:last-child) {
       margin-bottom: 1.75rem!important;
      }

      #sidebar {
        width: 75%; 
      }

      @media screen and (min-width: 769px), print {
        .column.is-2_5, .column.is-2-tablet {
          flex: none;
          width: 20%;
        }
      }
</style>
    <script src="https://code.jquery.com/jquery-3.1.1.min.js" crossorigin="anonymous"></script>
</head>


<body>
  <section class="section">
    <div class="container">
      <div class="columns">
        <div class="column is-2_5">
          <div class="sticky">
            <figure class="image" style="width: 11.6rem; margin-top: 6px;">
              <img src="images/misc/homepage3.jpg">
            </figure>
            <div class="content">
              <h2 style="margin-top: 1em">Xuecheng Wu</h2>
              <p>
                01s | Multi-modal Learning<br/> 
                Xi'an City, Shaanxi<br/> 
                Xi'an Jiaotong University<br/>
                Origin: Xinxiang City, Henan<br/>
              </p>
            </div>
            <!-- social network icons -->
<!--             <div class="social">
              <a href="https://github.com/XuecWu" target="_blank">
                <span class="fab fa-github fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a;"></span>
              </a>
              <a href="https://scholar.google.com.hk/citations?user=MuTEp7sAAAAJ" target="_blank">
                <span class="fab fa-google fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px"></span>
              </a>
              <a href="mailto:xuecwu@gmail.com" target="_blank">
                <span class="fa-regular fa-envelope fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px"></span>
              </a>
            </div> -->
            <div class="social">
              <a href="https://github.com/XuecWu" target="_blank">
                <span class="fab fa-github fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a;"></span>
              </a>
              <a href="https://scholar.google.com.hk/citations?user=MuTEp7sAAAAJ" target="_blank">
                <span class="fab fa-google fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px"></span>
              </a>
              <a href="mailto:xuecwu@gmail.com" target="_blank">
                <span class="fa-regular fa-envelope fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px"></span>
              </a>
              <a href="javascript:void(0);" title="WeChat" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px;" onmouseover="showWeChatQRCode()" onmouseout="hideWeChatQRCode()">
                <span class="fab fa-weixin fa-2x"></span>
              </a>
            </div>
            
            <div id="wechat-qr-code" style="display: none; position: absolute; z-index: 100;">
              <img src="images/misc/wechat2.jpg" alt="WeChat QR Code" style="width: 200px; height: 200px;" />
            </div>
            
            <script>
            function showWeChatQRCode() {
              var qrCode = document.getElementById('wechat-qr-code');
              qrCode.style.display = 'block';
            }
            
            function hideWeChatQRCode() {
              var qrCode = document.getElementById('wechat-qr-code');
              qrCode.style.display = 'none';
            }
            </script>
            
            <style>
            .fab.fa-weixin.fa-2x {
              color: #4a4a4a;
            }
            .fab.fa-weixin.fa-2x:hover {
              color: #00ff00;
            }
            </style>


            <div id="sidebar" class="menu sticky is-hidden-mobile">
              <!-- <p class="menu-label"><b>Quick Links</b></p> -->
              <ul class="menu-list">
                <li><a href="#intro">About Me</a></li>
                <li><a href="#news">News</a></li>
                <li><a href="#experience">Experience</a></li>
                <li><a href="#publications">Publications</a></li>
<!--                 <li><a href="#awards">Project Experience</a></li> -->
                <li><a href="#Awards">Awards</a></li>
                <li><a href="#Honors">Honors</a></li>
                <li><a href="#Academic Services">Academic Services</a></li>
                <li><a href="#Kind Assistance">Kind Assistance</a></li>
<!--                 <script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=K5mXqzOGNWeXE2Ezi93zbcP2GhxzuJjlVPOeC5nKM24&cl=ffffff&w=a"></script> -->
                <script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=8SUH0anSrOSbYt9jGqUOIVDF_nbIFHlEyDrM0-Tyc4E&cl=ffffff&w=a"></script>
<!--                 <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=cB6il4B36H3yx_wuGYRX__86Hp3X7WqnxlyjrsHRIEg&cl=ffffff&w=a"></script> -->
<!--                 <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=cB6il4B36H3yx_wuGYRX__86Hp3X7WqnxlyjrsHRIEg&co=2a5471&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script> -->
              </ul>
            </div>
          </div>



        </div>
        <div class="column right-panel">
          <div class="content">


            <!--About Me-->
            <h2 id="intro">âœ¨About Me</h2>
            <p>
              I'm currently a second-year master student majored in computer technology at the School of Computer Science and Technology, <a href="https://www.xjtu.edu.cn/" target="_blank">Xi'an Jiaotong University</a> (XJTU), supervised by Prof. <a href="https://gr.xjtu.edu.cn/en/web/hlsun" target="_blank">Heli Sun</a>. My research interest lies in deep learning and multi-media computing, primarily focusing on large-scale self-supervised video understanding, multi-modal large langugae models (MLLMs), and misinfo detection (Deepfake &amp; AIGC).
            </p>
            <p>
              Prior to that, I recevied my B.E. degree at the School of Cyber Science and Engineering, <a href="https://www.zzu.edu.cn/" target="_blank">Zhengzhou University</a> (ZZU), where I worked closely with Prof. <a href="https://xuejx7.github.io/" target="_blank">Junxiao Xue (PI, Zhejiang Lab)</a> and Prof. <a href="http://softschool.zzu.edu.cn/front/singleArticleDetail?id=4a453ec87076342b017076a5ace80011" target="_blank">Lei Shi (Vice Dean)</a>. Besides, as a student PI, I have led the eMotionAI Lab of Zhengzhou University Students innovative Entrepreneurial Base (North Campus) from 2021 to 2023.
            </p>

            <p>
              My CSDN Technology Blogs are located at <a href="https://blog.csdn.net/m0_47623548" target="_blank">HERE</a>.
            </p>
            
            <p>
              Please feel free to contact me if you are interested in my works and want to explore potential collaborations ğŸ™Œ.
            </p>

            <ul>
              <li><strong>Video Understanding:</strong> Multi-modal self-supervised learning</li>
              <li><strong>Multi-modal Large Language Models (MLLMs):</strong> Human-centric, Unified understanding and generation, and CoT reasoning</li>
              <li><strong>Misinfo Detection:</strong> Deepfake and AIGC detection</li>
            </ul>
          

            <h2 id="news">ğŸ“¢News</h2>
            <ul>
              <div style="width: 1000px;height: 160px; overflow-x:hidden;">
              <li>[08/2025] Eight paper are submitted to AAAI'26.</li>
              <li>[07/2025] One paper is accepted by MM'25 SVC Workshop!</li>
              <li>[07/2025] One paper is submitted to IEEE TCSVT.</li>
              <li>[07/2025] One paper is submitted to MM'25 SVC Workshop.</li>
              <li>[07/2025] One paper is submitted to IEEE TCSVT.</li>
              <li style="color:black;">[07/2025] Two papers are accepted by ACM MM'25!</li>
              <li style="color:black;">[06/2025] One paper is accpeted by IEEE SMC'25!</li>
              <li>[06/2025] One paper is submitted to Big Data Mining and Analytics.</li>
              <li>[06/2025] Served as a reviewer for EMNLP'25.</li>
              <li>[06/2025] One paper is submitted to ACM MM'25 Grand Challenge.</li>
              <li>[05/2025] One paper is submitted to Intelligent Computing.</li>
              <li>[05/2025] One paper is submitted to EMNLP'25.</li>
              <li>[05/2025] Four papers are submitted to NeurIPS'25.</li>
              <li>[05/2025] Served as a reviewer for ACM MM'25.</li>
              <li style="color:black;">[04/2025] One paper is accpeted by Big Data Mining and Analytics!</li>
              <li style="color:black;">[04/2025] Three papers are accepted by ACM ICMR'25!</li>
              <li>[04/2025] Five papers are submitted to ACM MM'25.</li>
              <li style="color:black;">[04/2025] One paper is accepted by CVPR'25 NTIRE Challenge!</li>
              <li style="color:black;">[04/2025] Three papers are accepted by IJCNN'25!</li>
              <li>[03/2025] One paper is submitted to IEEE SMC'25.</li>
              <li>[03/2025] One paper is submitted to CVPR'25 NTIRE Challenge.</li>
              <li style="color:gray;">[03/2025] One paper is submitted to ICCV'25ğŸˆ.</li>
              <li style="color:black;">[02/2025] Two papers are accepted by CVPR'25!</li>
              <li>[02/2025] Three papers are submitted to ICMR'25.</li>
              <li style="color:gray;">[01/2025] One paper is submitted to IJCAI'25ğŸˆ.</li>
              <li>[01/2025] Three papers are submitted to IJCNN'25.</li>
              <li>[12/2024] One paper is submitted to ACL'25.</li>
              <li style="color:gray;">[12/2024] Three papers are submitted to ICME'25ğŸˆ.</li>
              <li>[11/2024] Five papers are submitted to CVPR'25.</li>
              <li>[11/2024] One paper is submitted to Big Data Mining and Analytics.</li>
              <li>[11/2024] Served as a reviewer for CVPR'25.</li>
              <li>[10/2024] Served as a reviewer for WWW'25.</li>
              <li style="color:gray;">[10/2024] One paper is submitted to WWW'25ğŸˆ.</li>
              <li style="color:gray;">[09/2024] One paper is submitted to ICASSP'25ğŸˆ.</li>
              <li style="color:gray;">[08/2024] One paper is submitted to AAAI'25ğŸˆ.</li>
              <li style="color:black;">[08/2024] One paper is accpeted by Big Data Mining and Analytics!</li>
              <li style="color:black;">[07/2024] One paper is accpeted by ACM MM'24!</li>
              <li>[05/2024] Served as a reviewer for NeurIPS'24.</li>
              <li>[03/2024] Served as a reviewer for ACM MM'24.</li>
              </div>
            </ul>
            
            <!--Experience-->
            <h2 id="experience" style="margin-bottom: 25px;">ğŸ˜˜Experience</h2>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/ByteDance.png" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Research Intern</b> | Data-Douyin, ByteDance<br>
                    Period: 04/2025 - Present. Mentor: <a href="https://scholar.google.com.hk/citations?user=jvlDhkcAAAAJ&hl=zh-CN&oi=ao" target="_blank">Dingkang Yang</a> &amp; <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=FRW7i80AAAAJ" target="_blank">Xiao Liang</a>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/MeiTuan-new.png" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Research Intern</b> | Multi-modal Evaluation Group, Foundation LMMs Team<br>
                    Period: 01/2025 - Present. Mentor: Jiaxing Liu &amp; Xiaoyu Li
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/xjtu_logo.png" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Member</b> | Data Intelligence and Social Governance Lab, Xi'an Jiaotong University<br>
                    Period: 09/2023 - Present. Supervisor: Prof. <a href="https://gr.xjtu.edu.cn/en/web/hlsun" target="_blank">Heli Sun</a>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/renminwang.jpg" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Visiting Stundent</b> | State Key Laboratory of Communication Content Cognition<br>
<!--                     Time: 8/2024 - Present. Advisor:  -->
                    Period: 10/2023 - 10/2024. Supervisor: Prof. <a href="https://gr.xjtu.edu.cn/en/web/hlsun" target="_blank">Heli Sun</a>
                  </p>
                </div>
              </div>
            </article>
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/ZZU.jpg" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Student PI</b> | eMotionAI Lab, Zhengzhou University<br>
                    Period: 06/2021 - 06/2023. Advisor: Prof. <a href="https://xuejx7.github.io/" target="_blank">Junxiao Xue</a>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/ZZU.jpg" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Research Assistant</b> | Machine Vision Lab, Zhengzhou University<br>
                    Period: 06/2021 - 09/2021. Supervisor: Prof. <a href=http://softschool.zzu.edu.cn/front/singleArticleDetail?id=4a453ec870757da5017075a99c740021" target="_blank">Jianhong Ma</a>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/ZZU.jpg" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Research Assistant</b> | Computational Learning Lab, Zhengzhou University<br>
                    Period: 09/2020 - 06/2023. Supervisor: Prof. <a href="https://xuejx7.github.io/" target="_blank">Junxiao Xue</a>
                  </p>
                </div>
              </div>
            </article>
            

<!--             <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/UST1.jpg" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Research Intern</b> | CityMind Lab, HKUST(GZ)<br>
                    Time: 4/2023 - 10/2023. Advisor: Prof. <a href="https://scholar.google.com/citations?user=n9cODgcAAAAJ" target="_blank">Yuxuan Liang</a> (<a href="https://www.hkust-gz.edu.cn/academics/hubs-and-thrust-areas/systems-hub/intelligent-transportation/" target="_blank">IT Thrust</a> & <a href="https://www.hkust-gz.edu.cn/academics/hubs-and-thrust-areas/information-hub/data-science-and-analytics/" target="_blank">DSA Thrust</a>)
                  </p>
                </div>
              </div>
            </article> -->

            <!--Publications-->
<!--             <h2 id="publications">
              Publications
              <span style="font-size: 1rem;margin-left: 1rem;position: relative;bottom: .2rem;">
                <a href="https://scholar.google.com/citations?hl=en&user=BGUdPBAAAAAJ" target="_blank" style="font-size: 21px;">
                  [Google Scholar]
                </a>
              </span>
            </h2> -->
            <h2 id="publications" style="margin-bottom: 25px;">ğŸ˜ Selected Works</h2>
            
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/AVF-MAE++.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>AVF-MAE++: Scaling Affective Video Facial Masked Autoencoders via Efficient Audio-Visual Self-Supervised Learning</b><br>
                    <b>Xuecheng Wu</b>, Heli Sun<sup>&dagger;</sup>, Yifan Wang, Jiayu Nie, Jie Zhang, Yabing Wang, Junxiao Xue, Liang He<br>
                    <i><b>IEEE/CVF CVPR, 2025</b></i><br>
                    <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Wu_AVF-MAE_Scaling_Affective_Video_Facial_Masked_Autoencoders_via_Efficient_Audio-Visual_CVPR_2025_paper.html" target="_blank">[Paper]</a>
                    
                    <a href="https://github.com/XuecWu/AVF-MAE" target="_blank">[Code]</a>
                    <em class="blue"><b>Poster</b></em>
                  </p>
                </div>
              </div>
            </article>
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/eMotions.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Towards Emotion Analysis in Short-form Videos: A Large-Scale Dataset and Baseline</b><br>
                    <b>Xuecheng Wu</b>, Heli Sun<sup>&dagger;</sup>, Junxiao Xue, Jiayu Nie, Xiangyan Kong, Ruofan Zhai, Liang He<br>
<!--                     <i>ACM International World Wide Web Conference (<b>WWW</b>), 2024</i><br> -->
                    <i><b>ACM ICMR, 2025</b></i><br>
                    <a href="https://arxiv.org/pdf/2311.17335" target="_blank">[Paper]</a>
                    <a href="https://github.com/XuecWu/eMotions" target="_blank">[Code]</a>
                  </p>
                </div>
              </div>
            </article>


            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/JTD-UAV-new.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>JTD-UAV: MLLM-Enhanced Joint Tracking and Description Framework for Anti-UAV Systems</b><br>
                    Yifan Wang*, Jian Zhao*, Zhaoxin Fan<sup>&dagger;</sup>, Xin Zhang, <b>Xuecheng Wu</b>, Yudian Zhang, Lei Jin, Xinyue Li, Gang Wang<sup>&dagger;</sup>, Mengxi Jia, Ping Hu, Zheng Zhu, Xuelong Li<br>
                    <i><b>IEEE/CVF CVPR, 2025</b></i><br>
                    <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Wang_JTD-UAV_MLLM-Enhanced_Joint_Tracking_and_Description_Framework_for_Anti-UAV_Systems_CVPR_2025_paper.html" target="_blank">[Paper]</a>
                    <em class="blue"><b>Poster</b></em>
                  </p>
                </div>
              </div>
            </article>
            

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/ViC-Bench.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>ViC-Bench: Benchmarking Visual-Interleaved Chain-of-Thought Capability in MLLMs with Free-Style Intermediate State Representations</b><br>
                    <b>Xuecheng Wu</b>*, Jiaxing Liu*, Heli Sun<sup>&dagger;</sup>, Danlei Huang, Xiaoyu Li<sup>&dagger;</sup>, Yifan Wang, Chen Chen, Liya Ma, Xuezhi Cao, Junxiao Xue, Liang He<br>
                    <i><b>arXiv, 2025</b></i><br>
                    <a href="https://arxiv.org/pdf/2505.14404" target="_blank">[Paper]</a>
                    <a href="https://huggingface.co/datasets/meituan/ViC-Bench" target="_blank">[Dataset]</a>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/LLaVA-World.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>LLaVA-World: Benchmarking and Enhancing Fine-Grained Open-World Knowledge Understanding for MLLMs</b><br>
                    Yifan Wang*, <b>Xuecheng Wu</b>*, Yuhao Dong, Zuyan Liu, Jia Zhang, Qi Zhang, Winston Hu, Yongming Rao<sup>&dagger;</sup> (*: Equal Contribution.)<br>
                    <i><b>Under Review, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/MA-YOLO.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>3A-YOLO: New Real-time Object Detectors with Triple Discriminative Awareness and Coordinated Representations</b><br>
                    <b>Xuecheng Wu</b>*, Junxiao Xue*<sup>&dagger;</sup>, Liangyu Fu, Jiayu Nie, Danlei Huang, Xinyi Yin<br>
                    <i><b>IEEE SMC, 2025</b></i><br>
                    <a href="https://arxiv.org/pdf/2412.07168" target="_blank">[Paper]</a>
                  </p>
                </div>
              </div>
            </article>

          
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/Magnifier.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Magnifier: A Pluggable Framework for Enhanced High-Resolution Image Comprehension in Multi-modal Large Language Models</b><br>
                    Yifan Wang, Yunfei Wu, Xin Li<sup>&dagger;</sup>, <b>Xuecheng Wu</b>, Wentao Zhang, Haoyu Cao, Yinsong Liu, Deqiang Jiang, Xing Sun, Feiyue Huang<sup>&dagger;</sup><br>
                    <i><b>Under Review, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/TokenFocusVQA.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>TokenFocus-VQA: Enhancing Text-to-Image Evaluation with Position-Specific Probability Loss and Multi-Perspective Aggregations on LVLMs</b><br>
                    Zijian Zhang, Xunhui Zheng, <b>Xuecheng Wu</b>, Chong Peng<sup>&dagger;</sup>, Xuezhi Cao<br>
                    <i><b>IEEE/CVF CVPRW, 2025</b></i><br>
                    <a href="http://arxiv.org/abs/2504.07556" target="_blank">[Paper]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/HKD4VLM.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>HKD4VLM: A Progressive Hybrid Knowledge Distillation Framework for Robust Multimodal Hallucination and Factuality Detection in VLMs</b><br>
                    Zijian Zhang*, <b>Xuecheng Wu</b>*, Danlei Huang, Siyu Yan, Chong Peng<sup>&dagger;</sup>, Xuezhi Cao (*: Equal Contribution.)<br>
                    <i><b>Under Review, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>
            
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/AV-LGNN.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Building Robust Video-Level Deepfake Detection via Audio-Visual Local-Global Interactions</b><br>
                    Yifan Wang*, <b>Xuecheng Wu</b>*, Jia Zhang, Mohan Jing, Keda Lu, Jun Yu<sup>&dagger;</sup>, Wen Su, Fang Gao, Qingsong Liu, Jianqing Sun, Jiaen Liang (*: Equal Contribution and Radom Order.)<br>
<!--                     <i>ACM International World Wide Web Conference (<b>WWW</b>), 2024</i><br> -->
                    <i><b>ACM International Conference on Multimedia (<b>MM</b>), 2024</b></i><br>
                    <a href="https://dl.acm.org/doi/abs/10.1145/3664647.3688985" target="_blank">[Paper]</a>
<!--                     <em class="blue"><b>Oral Presentation</b></em>  -->
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/DDSE.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>DDSE: A Decoupled Dual-Stream Enhanced Framework for Multimodal Sentiment Analysis with Text-Centric SSM</b><br>
                    Shenjie Jiang, Zhuoyu Wang, <b>Xuecheng Wu</b>, Hongru Ji, Mingxin Li, Xianghua Li, Chao Gao<br>
                    <i><b>ACM MM, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/å¯ä¿¡-MER.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>A Trustworthy Method for Multimodal Emotion Recognition</b><br>
                    Junxiao Xue, Xiaozhen Liu<sup>&dagger;</sup>, Jie Wang, <b>Xuecheng Wu</b>, Bin Wu<br>
                    <i><b>Big Data Mining and Analytics, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/Doc-CoT.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>LR-Doc: Benchmarking and Advancing Long Document Reasoning in MLLMs with Learned Priors</b><br>
                    Yifan Wang*, <b>Xuecheng Wu</b>*, Danlei Huang, Zhaoxin Fan<sup>&dagger;</sup>, Xinyi Yin, Tingqi Hu, Yang Xiao, Zhe Gao, Jun Xie, Xin Fu, Liang Xie<sup>&dagger;</sup> <br>
                    <i><b>Under Review, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/MM-AntiUAV.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>MM-AntiUAV: A Comprehensive Benchmark for Multi-UAV Tracking and Intent Recognition</b><br>
                    Yifan Wang*, Jian Zhao*, <b>Xuecheng Wu</b>, Xin Zhang, Danlei Huang, Zhaoxin Fan<sup>&dagger;</sup>, Gang Wang<sup>&dagger;</sup>, Lei Jin, Jianan Li, Xuelong Li <br>
                    <i><b>Under Review, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/DSACap.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>DSACap: Enhancing Visual-Semantic Alignment with Diffusion-based Framework for Image Captioning</b><br>
                    Liangyu Fu, Junbo Wang, Yuke Li, Qiangguo Jin, Hongsong Wang, Ya Jing, Linjiang Huang, Liang Yao, Jiangbin Zheng, <b>Xuecheng Wu</b>, Zhiyong Wang<br>
                    <i><b>ACM MM, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/ç»¼è¿°.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Affective Video Content Analysis: Decade Review and New Perspectives</b><br>
                    Junxiao Xue, Jie Wang<sup>&dagger;</sup>, Xiaozhen Liu, Qian Zhang, <b>Xuecheng Wu</b><br>
                    <i><b>Big Data Mining and Analytics,2024</b></i><br>
                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10807333" target="_blank">[Paper]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/PTSR.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>PTSR: A Unified Patch Tokenization, Selection and Representation Framework for Efficient Micro-expression Recognition</b><br>
                    Liangyu Fu, Junbo Wang, Qiangguo Jin, Yining Zhu, Hongsong Wang, Yuke Li, <b>Xuecheng Wu</b>, Zhiyong Wang<sup>&dagger;</sup><br>
                    <i><b>ACM ICMR, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>


            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/TACR-YOLO.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>TACR-YOLO: A Real-time Detection Framework for Abnormal Human Behaviors Enhanced with Coordinate and Task-Aware Representations</b><br>
                    Xinyi Yin, Wenbo Yuan, <b>Xuecheng Wu</b><sup>&dagger;</sup>, Liangyu Fu, Danlei Huang<br>
                    <i><b>IJCNN, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/InfoSyncNet.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>InfoSyncNet: Information Synchronization Temporal Convolutional Network for Visual Speech Recognition</b><br>
                    Junxiao Xue, Xiaozhen Liu<sup>&dagger;</sup>, <b>Xuecheng Wu</b>, Fei Yu, Jun Wang<br>
                    <i><b>IJCNN, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/FAMNet.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>FAMNet: Integrating 2D and 3D Features for Micro-expression Recognition via Multi-task Learning and Hierarchical Attention</b><br>
                    Liangyu Fu, <b>Xuecheng Wu</b><sup>&dagger;</sup>, Danlei Huang, Xinyi Yin<br>
                    <i><b>IJCNN, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/EPIR.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>EPIR: An Efficient Patch Tokenization, Integration and Representation Framework for Micro-expression Recognition</b><br>
                    Liangyu Fu, Junbo Wang, Yuke Li, Yining Zhu, Hongsong Wang, <b>Xuecheng Wu</b>, Kun Hu<br>
                    <i><b>IEEE TCSVT'25, Under Review</b></i><br>
                  </p>
                </div>
              </div>
            </article>
            
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/Masks.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>A Method on Mask Wearing Detection of Natural Population Based on Improved YOLOv4</b><br>
                    Junxiao Xue*, <b>Xuecheng Wu</b>*, Shihao Wang, Mengmeng Tian, Lei Shi<sup>&dagger;</sup><br>
                    <i><b>Journal of Zhengzhou University (Engineering Science), 2022</b></i><br>
                    <a href="https://xueshu.baidu.com/usercenter/paper/show?paperid=181508q07a3b0280ha4x0ae02x189564&site=xueshu_se" target="_blank">[Paper]</a><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/MirrorDiff.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>MirrorDiff: Learning Mirror Diffusion for Image Captioning via Regeneration</b><br>
                    Junbo Wang, Liangyu Fu, Yining Zhu, Qiangguo Jin, Hongsong Wang, Yuke Li, <b>Xuecheng Wu</b>, Kun Hu<sup>&dagger;</sup><br>
                    <i><b>ACM ICMR, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/ICVNet.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>ICVNet: A Method on Cross-modal Fusion of Short Video Emotion Recognition</b><br>
                    Junxiao Xue*, <b>Xuecheng Wu</b>*, Qian Zhang, Mengmeng Tian, Lanhang Zhai, Lei Shi<sup>&dagger;</sup><br>
                    <i><b>Chinese Journal of Ergonomics, 2022</b></i><br>
                    <a href="https://xueshu.baidu.com/usercenter/paper/show?paperid=1s4d06g079120ju00m160jk088130321&site=xueshu_se" target="_blank">[Paper]</a><br>
                  </p>
                </div>
              </div>
            </article>


            <h2 id="Awards">ğŸ‰Awards</h2>
            <ul>
              <li>2025å¹´ACM Multimediaå¤§ä¼š Deepfakes1M++å…¨çƒæŒ‘æˆ˜èµ› <strong>å† å†›</strong></li>
              <li>2025å¹´ACM Multimediaå¤§ä¼š Responsible AIå…¨çƒæŒ‘æˆ˜èµ› <strong>å† å†›</strong></li>
              <li>2025å¹´å…¨å›½å¤§å­¦ç”Ÿè½¯ä»¶åˆ›æ–°å¤§èµ› <strong>è¥¿åŒ—èµ›åŒºä¸€ç­‰å¥– &amp; å…¨å›½ä¸‰ç­‰å¥–</strong></li>
              <li>2025å¹´CVPR'25 NTIRE-æ–‡ç”Ÿå›¾æ¨¡å‹è´¨é‡è¯„ä¼°å…¨çƒæŒ‘æˆ˜èµ› <strong>äºšå†›</strong></li>
              <li>2024å¹´ç¬¬åä¹å±Š"æŒ‘æˆ˜æ¯"å…¨å›½å¤§å­¦ç”Ÿè¯¾å¤–å­¦æœ¯ç§‘æŠ€ä½œå“ç«èµ›"æ­æ¦œæŒ‚å¸…"ä¸“é¡¹èµ› <strong>å…¨å›½ä¸€ç­‰å¥–</strong></li>
              <li>2024å¹´"ä¸­å›½ç½‘è°·Â·åä¸ºæ¯"ä¸­å›½ç ”ç©¶ç”Ÿç½‘ç»œå®‰å…¨åˆ›æ–°å¤§èµ› <strong>å…¨å›½ä¸‰ç­‰å¥–</strong></li>
              <li>2024å¹´ACM Multimediaå¤§ä¼š Deepfakes1Må…¨çƒæŒ‘æˆ˜èµ› <strong>å† å†›</strong></li>
              <li>2024å¹´"åä¸ºæ¯"ç¬¬å…­å±Šä¸­å›½ç ”ç©¶ç”Ÿäººå·¥æ™ºèƒ½åˆ›æ–°å¤§èµ› <strong>å…¨å›½ä¸‰ç­‰å¥–</strong></li>
              <li>2024å¹´ç¬¬åäº”å±Šä¸­å›½å¤§å­¦ç”ŸæœåŠ¡å¤–åŒ…åˆ›æ–°åˆ›ä¸šå¤§èµ› <strong>çœçº§äºŒç­‰å¥– &amp; å…¨å›½ä¸‰ç­‰å¥–</strong></li>
              <li>2024å¹´ä¸­å›½é«˜æ ¡è®¡ç®—æœºå¤§èµ›-ç½‘ç»œæŠ€æœ¯æŒ‘æˆ˜èµ› <strong>çœçº§äºŒç­‰å¥–</strong></li>
              <li>2022å¹´ç¬¬åäº”å±Šå…¨å›½å¤§å­¦ç”Ÿä¿¡æ¯å®‰å…¨ç«èµ›-ä½œå“èµ› <strong>å…¨å›½ä¸‰ç­‰å¥–</strong></li>
              <li>2022å¹´å…¨å›½å¤§å­¦ç”Ÿç‰©è”ç½‘è®¾è®¡ç«èµ› <strong>çœçº§ä¸€ç­‰å¥– &amp; å…¨å›½äºŒç­‰å¥–</strong></li>
              <li>2022å¹´ä¸­å›½é«˜æ ¡è®¡ç®—æœºå¤§èµ›-ç½‘ç»œæŠ€æœ¯æŒ‘æˆ˜èµ› <strong>çœçº§äºŒç­‰å¥– &amp; å…¨å›½ä¸‰ç­‰å¥–</strong></li>
              <li>2022å¹´å¤§å­¦ç”Ÿåˆ›æ–°åˆ›ä¸šè®­ç»ƒè®¡åˆ’ <strong>æ²³å—çœæ•™è‚²å…æš¨éƒ‘å·å¤§å­¦åˆ›æ–°é‡ç‚¹é¡¹ç›® (é¡¹ç›®ä¸»æŒäºº)</strong></li>
              <li>2022å¹´ä¸­å›½å¤§å­¦ç”Ÿè®¡ç®—æœºè®¾è®¡å¤§èµ› <strong>çœçº§ä¸‰ç­‰å¥–</strong></li>
              <li>2021å¹´å…¨å›½å¤§å­¦ç”Ÿç‰©è”ç½‘è®¾è®¡ç«èµ› <strong>çœçº§ä¸€ç­‰å¥– &amp; å…¨å›½ä¸‰ç­‰å¥–</strong></li>
              <li>2021å¹´ä¸­å›½é«˜æ ¡è®¡ç®—æœºå¤§èµ›-ç½‘ç»œæŠ€æœ¯æŒ‘æˆ˜èµ› <strong>çœçº§ä¸‰ç­‰å¥–</strong></li>
              <li>2021å¹´ä¸­å›½å¤§å­¦ç”Ÿè®¡ç®—æœºè®¾è®¡å¤§èµ› <strong>çœçº§ä¸‰ç­‰å¥–</strong></li>
              <li>2021å¹´ç¬¬åä¸ƒå±Š "æŒ‘æˆ˜æ¯"å¤§å­¦ç”Ÿè¯¾å¤–å­¦æœ¯ç§‘æŠ€ä½œå“ç«èµ› <strong>éƒ‘å·å¤§å­¦æ ¡çº§äºŒç­‰å¥–</strong></li>
              <li>2020å¹´å…¨å›½å¤§å­¦ç”Ÿè‹±è¯­ç«èµ› (NECCS) <strong>çœçº§ä¼˜ç§€å¥–</strong></li>
            </ul>


            <h2 id="Honors">ğŸ’–Honors</h2>
            <ul>
<!--               <li>Research and Innovation Scholarship of NPU (Top 3&lsquo;), 2024.</li> -->
              <li>è¥¿å®‰äº¤é€šå¤§å­¦2023-2024å­¦å¹´ç ”ç©¶ç”Ÿç‰¹ç­‰å¥–å­¦é‡‘</li>
              <li>è¥¿å®‰äº¤é€šå¤§å­¦2023-2024å­¦å¹´ä¼˜ç§€ç ”ç©¶ç”Ÿ</li>
              <li>è¥¿å®‰äº¤é€šå¤§å­¦-æµªæ½®é›†å›¢2023-2024å­¦å¹´ä¼˜ç§€ç ”ç©¶ç”Ÿå­¦ä¸šå¥–å­¦é‡‘</li>
              <li>2022è‡³2023å¹´åº¦ä¸­å›½å¤§å­¦ç”Ÿè‡ªå¼ºä¹‹æ˜Ÿ (<strong>è¯¥å¹´åº¦éƒ‘å·å¤§å­¦å”¯ä¸€å…¥é€‰; æ²³å—çœæ’åç¬¬ä¸€</strong>) <a href="https://www.zzu.edu.cn/info/1217/81980.htm" target="_blank">[Link]</a></li>
              <li>è¥¿å®‰äº¤é€šå¤§å­¦2023çº§ç ”ç©¶ç”Ÿæ–°ç”Ÿä¸€ç­‰å¥–å­¦é‡‘</li>
              <li>éƒ‘å·å¤§å­¦2023å±Šæ™®é€šæœ¬ç§‘ç”Ÿä¼˜ç§€æ¯•ä¸šè®ºæ–‡ (<strong>TOP 1.4%</strong>)</li>
              <li>2023å¹´åº¦éƒ‘å·å¤§å­¦ä¼˜ç§€æ¯•ä¸šç”Ÿ</li>
              <li>2023å¹´åº¦éƒ‘å·å¤§å­¦ç½‘ç»œç©ºé—´å®‰å…¨å­¦é™¢åä½³ä¼˜ç§€æ¯•ä¸šç”Ÿ</li>
              <li>2022è‡³2023å­¦å¹´éƒ‘å·å¤§å­¦ä¸€ç­‰å­¦ä¸šå¥–å­¦é‡‘</li>
              <li>2022å¹´åº¦éƒ‘å·å¤§å­¦<strong>æ ¡å›­ä¹‹æ˜Ÿ</strong></li>
              <li>éƒ‘å·å¤§å­¦2022-2023å­¦å¹´"èœœé›ªå†°åŸ"å¥–å­¦é‡‘</li>
              <li>éƒ‘å·å¤§å­¦2021è‡³2022å­¦å¹´ä¸‰å¥½å­¦ç”Ÿ</li>
              <li>éƒ‘å·å¤§å­¦2021è‡³2022å­¦å¹´ä¼˜ç§€å­¦ç”Ÿå¹²éƒ¨</li>
              <li>2022å¹´åº¦æ•™è‚²éƒ¨-åä¸º"æ™ºèƒ½åŸºåº§"å¥–å­¦é‡‘</li>
              <li>2021è‡³2022å­¦å¹´å›½å®¶åŠ±å¿—å¥–å­¦é‡‘</li>
              <li>2021å¹´åº¦æ²³å—çœé«˜æ ¡æ–‡æ˜å®¿èˆ (<strong>TOP 0.2%</strong>, å®¿èˆé•¿)</li>
              <li>2020è‡³2021å­¦å¹´å›½å®¶åŠ±å¿—å¥–å­¦é‡‘</li>
              <li>éƒ‘å·å¤§å­¦2020è‡³2021å­¦å¹´ä¸‰å¥½å­¦ç”Ÿ</li>
            </ul>


            <h2 id="Academic Services">ğŸŒ¹Academic Services</h2>
            <ul>
              <li>Conference Reviewer for 
                <br>&emsp;1. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
                <br>&emsp;2. IEEE/CVF International Conference on Computer Vision (ICCV)
                <br>&emsp;3. The Annual Conference on Neural Information Processing Systems (NeurIPS)
                <br>&emsp;4. ACM The Web Conference (WWW)
                <br>&emsp;5. CAAI International Conference on Artificial Intelligence (CICAI)
                <br>&emsp;6. ACM International Conference on Multimedia (MM)
                <br>&emsp;7. IEEE International Conference on Multimedia & Expo (ICME)
                <br>&emsp;8. IEEE BigData
                <br>&emsp;9. International Joint Conference on Neural Networks (IJCNN)
                <br>&emsp;10. IEEE International Conference on Advanced Visual and Signal-Based Systems (AVSS)
                <br>&emsp;11. IEEE International Conference on Systems, Man, and Cybernetics (SMC)
                <br>&emsp;12. Empirical Methods in Natural Language Processing (EMNLP)
              </li>
              <li>Journal Reviewer for 
                <br>&emsp;1. IEEE Transactions on Multimedia (TMM)
                <br>&emsp;2. Knowledge-based Systems (KBS)
                <br>&emsp;3. IEEE Transactions on Knowledge and Data Engineering (TKDE)
                <br>&emsp;4. Intelligent Computing
                <br>&emsp;5. ACM Transactions on Multimedia Computing Communications and Applications (TOMM)
              </li>
            </ul>


            <h2 id="Kind Assistance">ğŸ¥³Kind Assistance</h2>
            <ul>
              As a native student from Henan Province, I am deeply eager to make impacts on the developments of students at my alma mater, Zhengzhou University. I have successfully guided excellent undergraduates from our eMotionAI Lab to enter the graduate study phase through the recommendation-based exemption or entrance examination.
              The detailed information is listed as follows: 
                <br><strong>2024 Year Entrance</strong>. Liangyu Fu (Northwestern Polytechnical University), Mengli Dai (Harbin Institute of Technology), Qian Zhang (National University of Defense Technology), Rui Wang (Zhengzhou University).
                <br><strong>2025 Year Entrance</strong>. Jie Li (University of Science and Technology of China), Puhao Liu (Northwestern Polytechnical University), Wenbo Yuan (Xidian University), Mengjia Wang (Zhengzhou University), Qi Zhang (Xi'an Jiaotong University), Liduo Wang (Renmin University of China).
            </ul>

            
          </div>
        </div>
      </div>
    </div>

    <!-- Footer -->
    <footer class="container">
      <br><hr>
      <div class="row" style="text-align: center">
        Â© 2025 Xuecheng Wu (XuecWu3 & Conna)
      </div>
    </footer>
  </section>


  <script>

    var $hashList = $('.menu-list a'), offsetList, maxScrollHeight;

    $('#sidebar').on('click', 'a', function(){
      activate($(this))
    });
    
    $(window).on('resize', debounce(calculateBoundary, 300));

    $(document).on('scroll', debounce(judgeScroll, 300));

    calculateBoundary();
    judgeScroll();
    
    function  calculateBoundary() {
      offsetList = $hashList.map(function(idx, ele){
        return $(ele.hash).offset().top
      });
      maxScrollHeight = $(document).height() - $(window).height()
    }
    
    function judgeScroll() {
      var tps = $("html").scrollTop()
              ? $("html").scrollTop()
              : $("body").scrollTop(),
              len = offsetList.length;
      if(tps >= maxScrollHeight-10){
        activate($hashList.eq(len-1));
        return
      }
      for(var i=0; i<len; i++){
       if(tps+50<offsetList[i]){
          activate($hashList.eq(Math.max(0,i-1)));
          return
        }
      }
    }

    function activate(ele){
      $hashList.removeClass('is-active');
      ele.addClass('is-active');
    }

    function debounce(fn, delay) {
      var timeout = null;
      return function () {
        var args = arguments;
        var context = this;
        if (!timeout) {
          timeout = setTimeout(function () {
            timeout = 0;
            return fn.apply(context, args);
          }, delay);
        }
      };
    }



  </script>


</body>

</html>
