<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">  
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Xuecheng Wu's Homepage</title>
  <link href="css/bootstrap.css" rel='stylesheet' type='text/css' />
  <link rel="shortcut icon" type="image/x-icon" href="images/misc/personal.png">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans" rel="stylesheet">
  <!-- Bulma Version 0.7.5-->
  <link rel="stylesheet" href="https://unpkg.com/bulma@0.7.5/css/bulma.min.css" />
  <link href='css/style.css?_t=20200916' rel='stylesheet' type='text/css'>
  <script defer src="font-awesome/js/brands.min.js"></script>
  <script defer src="font-awesome/js/regular.min.js"></script>
  <script defer src="font-awesome/js/fontawesome.min.js"></script>
    <style>
      .red {
        color: rgb(238, 76, 44);
        font-style: normal;
      }
      .blue {
        color: rgb(238, 76, 44);
        font-style: normal;
      }
       
      #intro {
       margin-top: 0em !important;
      }
      
      .content h3 {
       margin-bottom: 1em!important;
       margin-top: 2em!important;
      }

      .content figure {
       width: 90%;
       display: flex;
       align-items: center;
       overflow: hidden;
       margin-left: auto!important;
       margin-right: auto!important;
      }
      
      .columns:not(:last-child) {
       margin-bottom: 1.75rem!important;
      }

      #sidebar {
        width: 75%; 
      }

      @media screen and (min-width: 769px), print {
        .column.is-2_5, .column.is-2-tablet {
          flex: none;
          width: 20%;
        }
      }
</style>
    <script src="https://code.jquery.com/jquery-3.1.1.min.js" crossorigin="anonymous"></script>
</head>


<body>
  <section class="section">
    <div class="container">
      <div class="columns">
        <div class="column is-2_5">
          <div class="sticky">
            <figure class="image" style="width: 11.6rem; margin-top: 6px;">
              <img src="images/misc/homepage3.jpg">
            </figure>
            <div class="content">
              <h2 style="margin-top: 1em">Xuecheng Wu</h2>
              <p>
                01s | Multi-modal Learning<br/> 
                Xi'an City, Shaanxi<br/> 
                Xi'an Jiaotong University<br/>
                Origin: Xinxiang City, Henan<br/>
              </p>
            </div>
            <!-- social network icons -->
<!--             <div class="social">
              <a href="https://github.com/XuecWu" target="_blank">
                <span class="fab fa-github fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a;"></span>
              </a>
              <a href="https://scholar.google.com.hk/citations?user=MuTEp7sAAAAJ" target="_blank">
                <span class="fab fa-google fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px"></span>
              </a>
              <a href="mailto:xuecwu@gmail.com" target="_blank">
                <span class="fa-regular fa-envelope fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px"></span>
              </a>
            </div> -->
            <div class="social">
              <a href="https://github.com/XuecWu" target="_blank">
                <span class="fab fa-github fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a;"></span>
              </a>
              <a href="https://scholar.google.com.hk/citations?user=MuTEp7sAAAAJ" target="_blank">
                <span class="fab fa-google fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px"></span>
              </a>
              <a href="mailto:xuecwu@gmail.com" target="_blank">
                <span class="fa-regular fa-envelope fa-2x" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px"></span>
              </a>
              <a href="javascript:void(0);" title="WeChat" style="display:inline; text-decoration: none; color: #4a4a4a; margin-left: 15px;" onmouseover="showWeChatQRCode()" onmouseout="hideWeChatQRCode()">
                <span class="fab fa-weixin fa-2x"></span>
              </a>
            </div>
            
            <div id="wechat-qr-code" style="display: none; position: absolute; z-index: 100;">
              <img src="images/misc/wechat2.jpg" alt="WeChat QR Code" style="width: 200px; height: 200px;" />
            </div>
            
            <script>
            function showWeChatQRCode() {
              var qrCode = document.getElementById('wechat-qr-code');
              qrCode.style.display = 'block';
            }
            
            function hideWeChatQRCode() {
              var qrCode = document.getElementById('wechat-qr-code');
              qrCode.style.display = 'none';
            }
            </script>
            
            <style>
            .fab.fa-weixin.fa-2x {
              color: #4a4a4a;
            }
            .fab.fa-weixin.fa-2x:hover {
              color: #00ff00;
            }
            </style>


            <div id="sidebar" class="menu sticky is-hidden-mobile">
              <!-- <p class="menu-label"><b>Quick Links</b></p> -->
              <ul class="menu-list">
                <li><a href="#intro">About Me</a></li>
                <li><a href="#news">News</a></li>
                <li><a href="#experience">Experience</a></li>
                <li><a href="#publications">Publications</a></li>
<!--                 <li><a href="#awards">Project Experience</a></li> -->
                <li><a href="#Awards">Awards</a></li>
                <li><a href="#Honors">Honors</a></li>
                <li><a href="#Academic Services">Academic Services</a></li>
                <li><a href="#Kind Assistance">Kind Assistance</a></li>
<!--                 <script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=K5mXqzOGNWeXE2Ezi93zbcP2GhxzuJjlVPOeC5nKM24&cl=ffffff&w=a"></script> -->
                <script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=8SUH0anSrOSbYt9jGqUOIVDF_nbIFHlEyDrM0-Tyc4E&cl=ffffff&w=a"></script>
<!--                 <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=cB6il4B36H3yx_wuGYRX__86Hp3X7WqnxlyjrsHRIEg&cl=ffffff&w=a"></script> -->
<!--                 <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=cB6il4B36H3yx_wuGYRX__86Hp3X7WqnxlyjrsHRIEg&co=2a5471&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script> -->
              </ul>
            </div>
          </div>



        </div>
        <div class="column right-panel">
          <div class="content">


            <!--About Me-->
            <h2 id="intro">✨About Me</h2>
            <p>
              I'm currently a second-year master student majored in computer technology at the School of Computer Science and Technology, <a href="https://www.xjtu.edu.cn/" target="_blank">Xi'an Jiaotong University</a> (XJTU), supervised by Prof. <a href="https://gr.xjtu.edu.cn/en/web/hlsun" target="_blank">Heli Sun</a>. My research interest lies in deep learning and multi-media computing, primarily focusing on large-scale self-supervised video understanding, multi-modal large langugae models (MLLMs), and misinfo detection (Deepfake &amp; AIGC).
            </p>
            <p>
              Prior to that, I recevied my B.E. degree at the School of Cyber Science and Engineering, <a href="https://www.zzu.edu.cn/" target="_blank">Zhengzhou University</a> (ZZU), where I worked closely with Prof. <a href="https://xuejx7.github.io/" target="_blank">Junxiao Xue (PI, Zhejiang Lab)</a> and Prof. <a href="http://softschool.zzu.edu.cn/front/singleArticleDetail?id=4a453ec87076342b017076a5ace80011" target="_blank">Lei Shi (Vice Dean)</a>. Besides, as a student PI, I have led the eMotionAI Lab of Zhengzhou University Students innovative Entrepreneurial Base (North Campus) from 2021 to 2023.
            </p>

            <p>
              My CSDN Technology Blogs are located at <a href="https://blog.csdn.net/m0_47623548" target="_blank">HERE</a>.
            </p>
            
            <p>
              Please feel free to contact me if you are interested in my works and want to explore potential collaborations 🙌.
            </p>

            <ul>
              <li><strong>Video Understanding:</strong> Multi-modal self-supervised learning</li>
              <li><strong>Multi-modal Large Language Models (MLLMs):</strong> Human-centric, Unified understanding and generation, and CoT reasoning</li>
              <li><strong>Misinfo Detection:</strong> Deepfake and AIGC detection</li>
            </ul>
          

            <h2 id="news">📢News</h2>
            <ul>
              <div style="width: 1000px;height: 160px; overflow-x:hidden;">
              <li>[08/2025] Eight paper are submitted to AAAI'26.</li>
              <li>[07/2025] One paper is accepted by MM'25 SVC Workshop!</li>
              <li>[07/2025] One paper is submitted to IEEE TCSVT.</li>
              <li>[07/2025] One paper is submitted to MM'25 SVC Workshop.</li>
              <li>[07/2025] One paper is submitted to IEEE TCSVT.</li>
              <li style="color:black;">[07/2025] Two papers are accepted by ACM MM'25!</li>
              <li style="color:black;">[06/2025] One paper is accpeted by IEEE SMC'25!</li>
              <li>[06/2025] One paper is submitted to Big Data Mining and Analytics.</li>
              <li>[06/2025] Served as a reviewer for EMNLP'25.</li>
              <li>[06/2025] One paper is submitted to ACM MM'25 Grand Challenge.</li>
              <li>[05/2025] One paper is submitted to Intelligent Computing.</li>
              <li>[05/2025] One paper is submitted to EMNLP'25.</li>
              <li>[05/2025] Four papers are submitted to NeurIPS'25.</li>
              <li>[05/2025] Served as a reviewer for ACM MM'25.</li>
              <li style="color:black;">[04/2025] One paper is accpeted by Big Data Mining and Analytics!</li>
              <li style="color:black;">[04/2025] Three papers are accepted by ACM ICMR'25!</li>
              <li>[04/2025] Five papers are submitted to ACM MM'25.</li>
              <li style="color:black;">[04/2025] One paper is accepted by CVPR'25 NTIRE Challenge!</li>
              <li style="color:black;">[04/2025] Three papers are accepted by IJCNN'25!</li>
              <li>[03/2025] One paper is submitted to IEEE SMC'25.</li>
              <li>[03/2025] One paper is submitted to CVPR'25 NTIRE Challenge.</li>
              <li style="color:gray;">[03/2025] One paper is submitted to ICCV'25🎈.</li>
              <li style="color:black;">[02/2025] Two papers are accepted by CVPR'25!</li>
              <li>[02/2025] Three papers are submitted to ICMR'25.</li>
              <li style="color:gray;">[01/2025] One paper is submitted to IJCAI'25🎈.</li>
              <li>[01/2025] Three papers are submitted to IJCNN'25.</li>
              <li>[12/2024] One paper is submitted to ACL'25.</li>
              <li style="color:gray;">[12/2024] Three papers are submitted to ICME'25🎈.</li>
              <li>[11/2024] Five papers are submitted to CVPR'25.</li>
              <li>[11/2024] One paper is submitted to Big Data Mining and Analytics.</li>
              <li>[11/2024] Served as a reviewer for CVPR'25.</li>
              <li>[10/2024] Served as a reviewer for WWW'25.</li>
              <li style="color:gray;">[10/2024] One paper is submitted to WWW'25🎈.</li>
              <li style="color:gray;">[09/2024] One paper is submitted to ICASSP'25🎈.</li>
              <li style="color:gray;">[08/2024] One paper is submitted to AAAI'25🎈.</li>
              <li style="color:black;">[08/2024] One paper is accpeted by Big Data Mining and Analytics!</li>
              <li style="color:black;">[07/2024] One paper is accpeted by ACM MM'24!</li>
              <li>[05/2024] Served as a reviewer for NeurIPS'24.</li>
              <li>[03/2024] Served as a reviewer for ACM MM'24.</li>
              </div>
            </ul>
            
            <!--Experience-->
            <h2 id="experience" style="margin-bottom: 25px;">😘Experience</h2>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/ByteDance.png" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Research Intern</b> | Data-Douyin, ByteDance<br>
                    Period: 04/2025 - Present. Mentor: <a href="https://scholar.google.com.hk/citations?user=jvlDhkcAAAAJ&hl=zh-CN&oi=ao" target="_blank">Dingkang Yang</a> &amp; <a href="https://scholar.google.com.hk/citations?hl=zh-CN&user=FRW7i80AAAAJ" target="_blank">Xiao Liang</a>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/MeiTuan-new.png" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Research Intern</b> | Multi-modal Evaluation Group, Foundation LMMs Team<br>
                    Period: 01/2025 - Present. Mentor: Jiaxing Liu &amp; Xiaoyu Li
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/xjtu_logo.png" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Member</b> | Data Intelligence and Social Governance Lab, Xi'an Jiaotong University<br>
                    Period: 09/2023 - Present. Supervisor: Prof. <a href="https://gr.xjtu.edu.cn/en/web/hlsun" target="_blank">Heli Sun</a>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/renminwang.jpg" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Visiting Stundent</b> | State Key Laboratory of Communication Content Cognition<br>
<!--                     Time: 8/2024 - Present. Advisor:  -->
                    Period: 10/2023 - 10/2024. Supervisor: Prof. <a href="https://gr.xjtu.edu.cn/en/web/hlsun" target="_blank">Heli Sun</a>
                  </p>
                </div>
              </div>
            </article>
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/ZZU.jpg" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Student PI</b> | eMotionAI Lab, Zhengzhou University<br>
                    Period: 06/2021 - 06/2023. Advisor: Prof. <a href="https://xuejx7.github.io/" target="_blank">Junxiao Xue</a>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/ZZU.jpg" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Research Assistant</b> | Machine Vision Lab, Zhengzhou University<br>
                    Period: 06/2021 - 09/2021. Supervisor: Prof. <a href=http://softschool.zzu.edu.cn/front/singleArticleDetail?id=4a453ec870757da5017075a99c740021" target="_blank">Jianhong Ma</a>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/ZZU.jpg" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Research Assistant</b> | Computational Learning Lab, Zhengzhou University<br>
                    Period: 09/2020 - 06/2023. Supervisor: Prof. <a href="https://xuejx7.github.io/" target="_blank">Junxiao Xue</a>
                  </p>
                </div>
              </div>
            </article>
            

<!--             <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/misc/UST1.jpg" class="img-logo">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Research Intern</b> | CityMind Lab, HKUST(GZ)<br>
                    Time: 4/2023 - 10/2023. Advisor: Prof. <a href="https://scholar.google.com/citations?user=n9cODgcAAAAJ" target="_blank">Yuxuan Liang</a> (<a href="https://www.hkust-gz.edu.cn/academics/hubs-and-thrust-areas/systems-hub/intelligent-transportation/" target="_blank">IT Thrust</a> & <a href="https://www.hkust-gz.edu.cn/academics/hubs-and-thrust-areas/information-hub/data-science-and-analytics/" target="_blank">DSA Thrust</a>)
                  </p>
                </div>
              </div>
            </article> -->

            <!--Publications-->
<!--             <h2 id="publications">
              Publications
              <span style="font-size: 1rem;margin-left: 1rem;position: relative;bottom: .2rem;">
                <a href="https://scholar.google.com/citations?hl=en&user=BGUdPBAAAAAJ" target="_blank" style="font-size: 21px;">
                  [Google Scholar]
                </a>
              </span>
            </h2> -->
            <h2 id="publications" style="margin-bottom: 25px;">😍 Selected Works</h2>
            
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/AVF-MAE++.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>AVF-MAE++: Scaling Affective Video Facial Masked Autoencoders via Efficient Audio-Visual Self-Supervised Learning</b><br>
                    <b>Xuecheng Wu</b>, Heli Sun<sup>&dagger;</sup>, Yifan Wang, Jiayu Nie, Jie Zhang, Yabing Wang, Junxiao Xue, Liang He<br>
                    <i><b>IEEE/CVF CVPR, 2025</b></i><br>
                    <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Wu_AVF-MAE_Scaling_Affective_Video_Facial_Masked_Autoencoders_via_Efficient_Audio-Visual_CVPR_2025_paper.html" target="_blank">[Paper]</a>
                    
                    <a href="https://github.com/XuecWu/AVF-MAE" target="_blank">[Code]</a>
                    <em class="blue"><b>Poster</b></em>
                  </p>
                </div>
              </div>
            </article>
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/eMotions.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Towards Emotion Analysis in Short-form Videos: A Large-Scale Dataset and Baseline</b><br>
                    <b>Xuecheng Wu</b>, Heli Sun<sup>&dagger;</sup>, Junxiao Xue, Jiayu Nie, Xiangyan Kong, Ruofan Zhai, Liang He<br>
<!--                     <i>ACM International World Wide Web Conference (<b>WWW</b>), 2024</i><br> -->
                    <i><b>ACM ICMR, 2025</b></i><br>
                    <a href="https://arxiv.org/pdf/2311.17335" target="_blank">[Paper]</a>
                    <a href="https://github.com/XuecWu/eMotions" target="_blank">[Code]</a>
                  </p>
                </div>
              </div>
            </article>


            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/JTD-UAV-new.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>JTD-UAV: MLLM-Enhanced Joint Tracking and Description Framework for Anti-UAV Systems</b><br>
                    Yifan Wang*, Jian Zhao*, Zhaoxin Fan<sup>&dagger;</sup>, Xin Zhang, <b>Xuecheng Wu</b>, Yudian Zhang, Lei Jin, Xinyue Li, Gang Wang<sup>&dagger;</sup>, Mengxi Jia, Ping Hu, Zheng Zhu, Xuelong Li<br>
                    <i><b>IEEE/CVF CVPR, 2025</b></i><br>
                    <a href="https://openaccess.thecvf.com/content/CVPR2025/html/Wang_JTD-UAV_MLLM-Enhanced_Joint_Tracking_and_Description_Framework_for_Anti-UAV_Systems_CVPR_2025_paper.html" target="_blank">[Paper]</a>
                    <em class="blue"><b>Poster</b></em>
                  </p>
                </div>
              </div>
            </article>
            

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/ViC-Bench.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>ViC-Bench: Benchmarking Visual-Interleaved Chain-of-Thought Capability in MLLMs with Free-Style Intermediate State Representations</b><br>
                    <b>Xuecheng Wu</b>*, Jiaxing Liu*, Heli Sun<sup>&dagger;</sup>, Danlei Huang, Xiaoyu Li<sup>&dagger;</sup>, Yifan Wang, Chen Chen, Liya Ma, Xuezhi Cao, Junxiao Xue, Liang He<br>
                    <i><b>arXiv, 2025</b></i><br>
                    <a href="https://arxiv.org/pdf/2505.14404" target="_blank">[Paper]</a>
                    <a href="https://huggingface.co/datasets/meituan/ViC-Bench" target="_blank">[Dataset]</a>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/LLaVA-World.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>LLaVA-World: Benchmarking and Enhancing Fine-Grained Open-World Knowledge Understanding for MLLMs</b><br>
                    Yifan Wang*, <b>Xuecheng Wu</b>*, Yuhao Dong, Zuyan Liu, Jia Zhang, Qi Zhang, Winston Hu, Yongming Rao<sup>&dagger;</sup> (*: Equal Contribution.)<br>
                    <i><b>Under Review, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/MA-YOLO.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>3A-YOLO: New Real-time Object Detectors with Triple Discriminative Awareness and Coordinated Representations</b><br>
                    <b>Xuecheng Wu</b>*, Junxiao Xue*<sup>&dagger;</sup>, Liangyu Fu, Jiayu Nie, Danlei Huang, Xinyi Yin<br>
                    <i><b>IEEE SMC, 2025</b></i><br>
                    <a href="https://arxiv.org/pdf/2412.07168" target="_blank">[Paper]</a>
                  </p>
                </div>
              </div>
            </article>

          
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/Magnifier.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Magnifier: A Pluggable Framework for Enhanced High-Resolution Image Comprehension in Multi-modal Large Language Models</b><br>
                    Yifan Wang, Yunfei Wu, Xin Li<sup>&dagger;</sup>, <b>Xuecheng Wu</b>, Wentao Zhang, Haoyu Cao, Yinsong Liu, Deqiang Jiang, Xing Sun, Feiyue Huang<sup>&dagger;</sup><br>
                    <i><b>Under Review, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/TokenFocusVQA.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>TokenFocus-VQA: Enhancing Text-to-Image Evaluation with Position-Specific Probability Loss and Multi-Perspective Aggregations on LVLMs</b><br>
                    Zijian Zhang, Xunhui Zheng, <b>Xuecheng Wu</b>, Chong Peng<sup>&dagger;</sup>, Xuezhi Cao<br>
                    <i><b>IEEE/CVF CVPRW, 2025</b></i><br>
                    <a href="http://arxiv.org/abs/2504.07556" target="_blank">[Paper]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/HKD4VLM.png">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>HKD4VLM: A Progressive Hybrid Knowledge Distillation Framework for Robust Multimodal Hallucination and Factuality Detection in VLMs</b><br>
                    Zijian Zhang*, <b>Xuecheng Wu</b>*, Danlei Huang, Siyu Yan, Chong Peng<sup>&dagger;</sup>, Xuezhi Cao (*: Equal Contribution.)<br>
                    <i><b>Under Review, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>
            
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/AV-LGNN.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Building Robust Video-Level Deepfake Detection via Audio-Visual Local-Global Interactions</b><br>
                    Yifan Wang*, <b>Xuecheng Wu</b>*, Jia Zhang, Mohan Jing, Keda Lu, Jun Yu<sup>&dagger;</sup>, Wen Su, Fang Gao, Qingsong Liu, Jianqing Sun, Jiaen Liang (*: Equal Contribution and Radom Order.)<br>
<!--                     <i>ACM International World Wide Web Conference (<b>WWW</b>), 2024</i><br> -->
                    <i><b>ACM International Conference on Multimedia (<b>MM</b>), 2024</b></i><br>
                    <a href="https://dl.acm.org/doi/abs/10.1145/3664647.3688985" target="_blank">[Paper]</a>
<!--                     <em class="blue"><b>Oral Presentation</b></em>  -->
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/DDSE.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>DDSE: A Decoupled Dual-Stream Enhanced Framework for Multimodal Sentiment Analysis with Text-Centric SSM</b><br>
                    Shenjie Jiang, Zhuoyu Wang, <b>Xuecheng Wu</b>, Hongru Ji, Mingxin Li, Xianghua Li, Chao Gao<br>
                    <i><b>ACM MM, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/可信-MER.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>A Trustworthy Method for Multimodal Emotion Recognition</b><br>
                    Junxiao Xue, Xiaozhen Liu<sup>&dagger;</sup>, Jie Wang, <b>Xuecheng Wu</b>, Bin Wu<br>
                    <i><b>Big Data Mining and Analytics, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/Doc-CoT.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>LR-Doc: Benchmarking and Advancing Long Document Reasoning in MLLMs with Learned Priors</b><br>
                    Yifan Wang*, <b>Xuecheng Wu</b>*, Danlei Huang, Zhaoxin Fan<sup>&dagger;</sup>, Xinyi Yin, Tingqi Hu, Yang Xiao, Zhe Gao, Jun Xie, Xin Fu, Liang Xie<sup>&dagger;</sup> <br>
                    <i><b>Under Review, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/MM-AntiUAV.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>MM-AntiUAV: A Comprehensive Benchmark for Multi-UAV Tracking and Intent Recognition</b><br>
                    Yifan Wang*, Jian Zhao*, <b>Xuecheng Wu</b>, Xin Zhang, Danlei Huang, Zhaoxin Fan<sup>&dagger;</sup>, Gang Wang<sup>&dagger;</sup>, Lei Jin, Jianan Li, Xuelong Li <br>
                    <i><b>Under Review, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/DSACap.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>DSACap: Enhancing Visual-Semantic Alignment with Diffusion-based Framework for Image Captioning</b><br>
                    Liangyu Fu, Junbo Wang, Yuke Li, Qiangguo Jin, Hongsong Wang, Ya Jing, Linjiang Huang, Liang Yao, Jiangbin Zheng, <b>Xuecheng Wu</b>, Zhiyong Wang<br>
                    <i><b>ACM MM, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/综述.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>Affective Video Content Analysis: Decade Review and New Perspectives</b><br>
                    Junxiao Xue, Jie Wang<sup>&dagger;</sup>, Xiaozhen Liu, Qian Zhang, <b>Xuecheng Wu</b><br>
                    <i><b>Big Data Mining and Analytics,2024</b></i><br>
                    <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=10807333" target="_blank">[Paper]</a>
                  </p>
                </div>
              </div>
            </article>

            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/PTSR.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>PTSR: A Unified Patch Tokenization, Selection and Representation Framework for Efficient Micro-expression Recognition</b><br>
                    Liangyu Fu, Junbo Wang, Qiangguo Jin, Yining Zhu, Hongsong Wang, Yuke Li, <b>Xuecheng Wu</b>, Zhiyong Wang<sup>&dagger;</sup><br>
                    <i><b>ACM ICMR, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>


            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/TACR-YOLO.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>TACR-YOLO: A Real-time Detection Framework for Abnormal Human Behaviors Enhanced with Coordinate and Task-Aware Representations</b><br>
                    Xinyi Yin, Wenbo Yuan, <b>Xuecheng Wu</b><sup>&dagger;</sup>, Liangyu Fu, Danlei Huang<br>
                    <i><b>IJCNN, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/InfoSyncNet.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>InfoSyncNet: Information Synchronization Temporal Convolutional Network for Visual Speech Recognition</b><br>
                    Junxiao Xue, Xiaozhen Liu<sup>&dagger;</sup>, <b>Xuecheng Wu</b>, Fei Yu, Jun Wang<br>
                    <i><b>IJCNN, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/FAMNet.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>FAMNet: Integrating 2D and 3D Features for Micro-expression Recognition via Multi-task Learning and Hierarchical Attention</b><br>
                    Liangyu Fu, <b>Xuecheng Wu</b><sup>&dagger;</sup>, Danlei Huang, Xinyi Yin<br>
                    <i><b>IJCNN, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/EPIR.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>EPIR: An Efficient Patch Tokenization, Integration and Representation Framework for Micro-expression Recognition</b><br>
                    Liangyu Fu, Junbo Wang, Yuke Li, Yining Zhu, Hongsong Wang, <b>Xuecheng Wu</b>, Kun Hu<br>
                    <i><b>IEEE TCSVT'25, Under Review</b></i><br>
                  </p>
                </div>
              </div>
            </article>
            
            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/Masks.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>A Method on Mask Wearing Detection of Natural Population Based on Improved YOLOv4</b><br>
                    Junxiao Xue*, <b>Xuecheng Wu</b>*, Shihao Wang, Mengmeng Tian, Lei Shi<sup>&dagger;</sup><br>
                    <i><b>Journal of Zhengzhou University (Engineering Science), 2022</b></i><br>
                    <a href="https://xueshu.baidu.com/usercenter/paper/show?paperid=181508q07a3b0280ha4x0ae02x189564&site=xueshu_se" target="_blank">[Paper]</a><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/MirrorDiff.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>MirrorDiff: Learning Mirror Diffusion for Image Captioning via Regeneration</b><br>
                    Junbo Wang, Liangyu Fu, Yining Zhu, Qiangguo Jin, Hongsong Wang, Yuke Li, <b>Xuecheng Wu</b>, Kun Hu<sup>&dagger;</sup><br>
                    <i><b>ACM ICMR, 2025</b></i><br>
                  </p>
                </div>
              </div>
            </article>

            
            <article class="columns">
              <div class="column is-3">
                <figure class="image">
                  <img src="images/publications/ICVNet.jpg">
                </figure>
              </div>
              <div class="column">
                <div class="content">
                  <p>
                    <b>ICVNet: A Method on Cross-modal Fusion of Short Video Emotion Recognition</b><br>
                    Junxiao Xue*, <b>Xuecheng Wu</b>*, Qian Zhang, Mengmeng Tian, Lanhang Zhai, Lei Shi<sup>&dagger;</sup><br>
                    <i><b>Chinese Journal of Ergonomics, 2022</b></i><br>
                    <a href="https://xueshu.baidu.com/usercenter/paper/show?paperid=1s4d06g079120ju00m160jk088130321&site=xueshu_se" target="_blank">[Paper]</a><br>
                  </p>
                </div>
              </div>
            </article>


            <h2 id="Awards">🎉Awards</h2>
            <ul>
              <li>2025年ACM Multimedia大会 Deepfakes1M++全球挑战赛 <strong>冠军</strong></li>
              <li>2025年ACM Multimedia大会 Responsible AI全球挑战赛 <strong>冠军</strong></li>
              <li>2025年全国大学生软件创新大赛 <strong>西北赛区一等奖 &amp; 全国三等奖</strong></li>
              <li>2025年CVPR'25 NTIRE-文生图模型质量评估全球挑战赛 <strong>亚军</strong></li>
              <li>2024年第十九届"挑战杯"全国大学生课外学术科技作品竞赛"揭榜挂帅"专项赛 <strong>全国一等奖</strong></li>
              <li>2024年"中国网谷·华为杯"中国研究生网络安全创新大赛 <strong>全国三等奖</strong></li>
              <li>2024年ACM Multimedia大会 Deepfakes1M全球挑战赛 <strong>冠军</strong></li>
              <li>2024年"华为杯"第六届中国研究生人工智能创新大赛 <strong>全国三等奖</strong></li>
              <li>2024年第十五届中国大学生服务外包创新创业大赛 <strong>省级二等奖 &amp; 全国三等奖</strong></li>
              <li>2024年中国高校计算机大赛-网络技术挑战赛 <strong>省级二等奖</strong></li>
              <li>2022年第十五届全国大学生信息安全竞赛-作品赛 <strong>全国三等奖</strong></li>
              <li>2022年全国大学生物联网设计竞赛 <strong>省级一等奖 &amp; 全国二等奖</strong></li>
              <li>2022年中国高校计算机大赛-网络技术挑战赛 <strong>省级二等奖 &amp; 全国三等奖</strong></li>
              <li>2022年大学生创新创业训练计划 <strong>河南省教育厅暨郑州大学创新重点项目 (项目主持人)</strong></li>
              <li>2022年中国大学生计算机设计大赛 <strong>省级三等奖</strong></li>
              <li>2021年全国大学生物联网设计竞赛 <strong>省级一等奖 &amp; 全国三等奖</strong></li>
              <li>2021年中国高校计算机大赛-网络技术挑战赛 <strong>省级三等奖</strong></li>
              <li>2021年中国大学生计算机设计大赛 <strong>省级三等奖</strong></li>
              <li>2021年第十七届 "挑战杯"大学生课外学术科技作品竞赛 <strong>郑州大学校级二等奖</strong></li>
              <li>2020年全国大学生英语竞赛 (NECCS) <strong>省级优秀奖</strong></li>
            </ul>


            <h2 id="Honors">💖Honors</h2>
            <ul>
<!--               <li>Research and Innovation Scholarship of NPU (Top 3&lsquo;), 2024.</li> -->
              <li>西安交通大学2023-2024学年研究生特等奖学金</li>
              <li>西安交通大学2023-2024学年优秀研究生</li>
              <li>西安交通大学-浪潮集团2023-2024学年优秀研究生学业奖学金</li>
              <li>2022至2023年度中国大学生自强之星 (<strong>该年度郑州大学唯一入选; 河南省排名第一</strong>) <a href="https://www.zzu.edu.cn/info/1217/81980.htm" target="_blank">[Link]</a></li>
              <li>西安交通大学2023级研究生新生一等奖学金</li>
              <li>郑州大学2023届普通本科生优秀毕业论文 (<strong>TOP 1.4%</strong>)</li>
              <li>2023年度郑州大学优秀毕业生</li>
              <li>2023年度郑州大学网络空间安全学院十佳优秀毕业生</li>
              <li>2022至2023学年郑州大学一等学业奖学金</li>
              <li>2022年度郑州大学<strong>校园之星</strong></li>
              <li>郑州大学2022-2023学年"蜜雪冰城"奖学金</li>
              <li>郑州大学2021至2022学年三好学生</li>
              <li>郑州大学2021至2022学年优秀学生干部</li>
              <li>2022年度教育部-华为"智能基座"奖学金</li>
              <li>2021至2022学年国家励志奖学金</li>
              <li>2021年度河南省高校文明宿舍 (<strong>TOP 0.2%</strong>, 宿舍长)</li>
              <li>2020至2021学年国家励志奖学金</li>
              <li>郑州大学2020至2021学年三好学生</li>
            </ul>


            <h2 id="Academic Services">🌹Academic Services</h2>
            <ul>
              <li>Conference Reviewer for 
                <br>&emsp;1. IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)
                <br>&emsp;2. IEEE/CVF International Conference on Computer Vision (ICCV)
                <br>&emsp;3. The Annual Conference on Neural Information Processing Systems (NeurIPS)
                <br>&emsp;4. ACM The Web Conference (WWW)
                <br>&emsp;5. CAAI International Conference on Artificial Intelligence (CICAI)
                <br>&emsp;6. ACM International Conference on Multimedia (MM)
                <br>&emsp;7. IEEE International Conference on Multimedia & Expo (ICME)
                <br>&emsp;8. IEEE BigData
                <br>&emsp;9. International Joint Conference on Neural Networks (IJCNN)
                <br>&emsp;10. IEEE International Conference on Advanced Visual and Signal-Based Systems (AVSS)
                <br>&emsp;11. IEEE International Conference on Systems, Man, and Cybernetics (SMC)
                <br>&emsp;12. Empirical Methods in Natural Language Processing (EMNLP)
              </li>
              <li>Journal Reviewer for 
                <br>&emsp;1. IEEE Transactions on Multimedia (TMM)
                <br>&emsp;2. Knowledge-based Systems (KBS)
                <br>&emsp;3. IEEE Transactions on Knowledge and Data Engineering (TKDE)
                <br>&emsp;4. Intelligent Computing
                <br>&emsp;5. ACM Transactions on Multimedia Computing Communications and Applications (TOMM)
              </li>
            </ul>


            <h2 id="Kind Assistance">🥳Kind Assistance</h2>
            <ul>
              As a native student from Henan Province, I am deeply eager to make impacts on the developments of students at my alma mater, Zhengzhou University. I have successfully guided excellent undergraduates from our eMotionAI Lab to enter the graduate study phase through the recommendation-based exemption or entrance examination.
              The detailed information is listed as follows: 
                <br><strong>2024 Year Entrance</strong>. Liangyu Fu (Northwestern Polytechnical University), Mengli Dai (Harbin Institute of Technology), Qian Zhang (National University of Defense Technology), Rui Wang (Zhengzhou University).
                <br><strong>2025 Year Entrance</strong>. Jie Li (University of Science and Technology of China), Puhao Liu (Northwestern Polytechnical University), Wenbo Yuan (Xidian University), Mengjia Wang (Zhengzhou University), Qi Zhang (Xi'an Jiaotong University), Liduo Wang (Renmin University of China).
            </ul>

            
          </div>
        </div>
      </div>
    </div>

    <!-- Footer -->
    <footer class="container">
      <br><hr>
      <div class="row" style="text-align: center">
        © 2025 Xuecheng Wu (XuecWu3 & Conna)
      </div>
    </footer>
  </section>


  <script>

    var $hashList = $('.menu-list a'), offsetList, maxScrollHeight;

    $('#sidebar').on('click', 'a', function(){
      activate($(this))
    });
    
    $(window).on('resize', debounce(calculateBoundary, 300));

    $(document).on('scroll', debounce(judgeScroll, 300));

    calculateBoundary();
    judgeScroll();
    
    function  calculateBoundary() {
      offsetList = $hashList.map(function(idx, ele){
        return $(ele.hash).offset().top
      });
      maxScrollHeight = $(document).height() - $(window).height()
    }
    
    function judgeScroll() {
      var tps = $("html").scrollTop()
              ? $("html").scrollTop()
              : $("body").scrollTop(),
              len = offsetList.length;
      if(tps >= maxScrollHeight-10){
        activate($hashList.eq(len-1));
        return
      }
      for(var i=0; i<len; i++){
       if(tps+50<offsetList[i]){
          activate($hashList.eq(Math.max(0,i-1)));
          return
        }
      }
    }

    function activate(ele){
      $hashList.removeClass('is-active');
      ele.addClass('is-active');
    }

    function debounce(fn, delay) {
      var timeout = null;
      return function () {
        var args = arguments;
        var context = this;
        if (!timeout) {
          timeout = setTimeout(function () {
            timeout = 0;
            return fn.apply(context, args);
          }, delay);
        }
      };
    }



  </script>


</body>

</html>
